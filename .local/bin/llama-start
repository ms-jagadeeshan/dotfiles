 /home/jagadeeshan/experiments/llama.cpp/build/bin/llama-server -hf ggml-org/Qwen2.5-Coder-1.5B-Q8_0-GGUF --port 8081 -c 32768 -ngl 99 -fa auto -ub 1024 -b 1024 -dt 0.1  --cache-reuse 256
